# -*- coding: utf-8 -*-
import pandas as pd
import requests
import json
import re
import time
import os
import sys
import argparse
from tqdm import tqdm
from datetime import datetime
import math

# ä¿®å¤Windowsæ§åˆ¶å°ç¼–ç é—®é¢˜ï¼ˆä½¿ç”¨line_bufferingç¡®ä¿å®æ—¶è¾“å‡ºï¼‰
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', line_buffering=True)
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', line_buffering=True)

# ç«‹å³è¾“å‡ºå¯åŠ¨ä¿¡æ¯ï¼Œç¡®ä¿è„šæœ¬æ­£åœ¨è¿è¡Œ
print("ğŸ”„ æ­£åœ¨åˆå§‹åŒ–...", flush=True)
# ================= é…ç½®åŒºåŸŸ =================
# 1. æ¨¡å‹é…ç½®
OLLAMA_URL = "http://localhost:11434/api/generate"
OLLAMA_API_URL = "http://localhost:11434/api"  # Ollama APIåŸºç¡€URL
MODEL_NAME = "qwen3:14b-q4_K_M"  # ä¿®æ”¹æ­¤å¤„åä¿å­˜æ–‡ä»¶ï¼Œé‡æ–°è¿è¡Œè„šæœ¬å³å¯ç”Ÿæ•ˆ

# 2. æ–‡ä»¶è·¯å¾„é…ç½®
INPUT_FILE = "F:\\XXX.xlsx"  # ä½ çš„é…ç½®æ–‡ä»¶è·¯å¾„
SHEET_NAME = "XXX_CONF"           # è¦æ£€æŸ¥çš„ Sheet åç§°
TARGET_COLUMN = "XXX"   # å­˜ä¸­æ–‡æ–‡æ¡ˆçš„é‚£ä¸€åˆ—çš„è¡¨å¤´åç§°ï¼ˆç¬¬3è¡Œè¡¨å¤´æ˜¯"text"ï¼Œä¼šè‡ªåŠ¨æ¨¡ç³ŠåŒ¹é…åˆ°"optional_string_text"ï¼‰
TARGET_COLUMN_INDEX = None  # å¯é€‰ï¼šå½“å­˜åœ¨å¤šä¸ªåŒååˆ—æ—¶ï¼ŒæŒ‡å®šä½¿ç”¨ç¬¬å‡ ä¸ªï¼ˆä»0å¼€å§‹ï¼ŒNoneè¡¨ç¤ºä½¿ç”¨ç¬¬ä¸€ä¸ªåŒ¹é…çš„åˆ—ï¼‰
# ç¤ºä¾‹ï¼šå¦‚æœæœ‰3ä¸ª"text"åˆ—ï¼ŒTARGET_COLUMN_INDEX=0è¡¨ç¤ºç¬¬1ä¸ªï¼Œ1è¡¨ç¤ºç¬¬2ä¸ªï¼Œ2è¡¨ç¤ºç¬¬3ä¸ª

# 3. è¡¨å¤´é…ç½®ï¼ˆé‡è¦ï¼ï¼‰
HEADER_ROWS = [0, 1, 2]  # ä½¿ç”¨ç¬¬1ã€2ã€3è¡Œä½œä¸ºè¡¨å¤´ï¼ˆå¯¹åº”Excelçš„ç¬¬1-3è¡Œï¼‰
# è¯´æ˜ï¼š
# - ç¬¬1è¡Œ: optional, string, text ç­‰ç±»å‹å®šä¹‰
# - ç¬¬2è¡Œ: string, bool, int64 ç­‰æ•°æ®ç±»å‹
# - ç¬¬3è¡Œ: text, editor_name, id ç­‰å­—æ®µå
# - ç¬¬4è¡Œ: ä¸­æ–‡è¯´æ˜ï¼ˆ"å¯¹ç™½å†…å®¹"ç­‰ï¼‰ä¼šè¢«è·³è¿‡
# - ç¬¬5è¡Œ: æ•°å­—è¡Œä¼šè¢«è·³è¿‡
# - ç¬¬6è¡Œå¼€å§‹: å®é™…æ•°æ®

# 4. æ£€æŸ¥å‚æ•°
BATCH_SIZE = 30  # æ¯æ¬¡å‘ç»™ AI 30 è¡Œæ•°æ®ï¼Œæ ¹æ®æ˜¾å­˜æƒ…å†µè°ƒæ•´ï¼Œå¤ªå¤§å®¹æ˜“å¹»è§‰
OUTPUT_FILE = f"{SHEET_NAME}_{TARGET_COLUMN}_Check_Report_{datetime.now().strftime('%Y%m%d')}.xlsx"  # æ–‡ä»¶ååŒ…å«æ—¥æœŸï¼Œé¿å…è¦†ç›–
# ===========================================

def get_check_prompt(batch_data):
    """
    æ„é€  Promptï¼Œè¦æ±‚è¿”å›ä¸¥æ ¼çš„ JSON æ ¼å¼ï¼ˆæ•´åˆæ´›å…‹ç‹å›½æ–‡æ¡ˆè§„èŒƒï¼‰
    """
    data_str = json.dumps(batch_data, ensure_ascii=False, indent=2)
    
    prompt = f"""ä½ æ˜¯æ´›å…‹ç‹å›½æ¸¸æˆæ–‡æ¡ˆå®¡æ ¸ä¸“å®¶ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹è§„èŒƒæ£€æŸ¥å‰§æƒ…å¯¹ç™½æ–‡æœ¬ï¼š

ã€å¿…æŸ¥é¡¹ã€‘
1. é”™åˆ«å­—ï¼ˆé‡ç‚¹ï¼šçš„åœ°å¾—ç”¨æ³•ã€æ‚‰æ‚‰ç´¢ç´¢â†’çª¸çª¸çª£çª£ï¼‰
2. è¯­ç—…ï¼ˆä¸»è¯­æ··ä¹±ã€ç¼ºå°‘ä¸»è¯­ã€æ­é…ä¸å½“ã€è¯æ€§è¯¯ç”¨ã€æ•°é‡è¡¨è¾¾æ··ä¹±ï¼‰
3. æˆè¯­é”™ç”¨ï¼ˆè´Ÿéš…é¡½æŠ—ã€å¨“å¨“é“æ¥ã€é€¡å·¡ä¸å‰ç­‰è´¬ä¹‰/è¤’ä¹‰è¯¯ç”¨ï¼‰
4. å¤šå­—/æ¼å­—
5. å†…å®¹åˆè§„:æ˜ç¡®è§¦åŠæ”¿æ²»æ•æ„Ÿã€æš´åŠ›è‰²æƒ…ã€é»„èµŒæ¯’ï¼Œä¸è¦è¿‡å¤šæ‰©å±•

ã€å¿½ç•¥é¡¹ã€‘
- é‡å¤å†…å®¹ã€éä¸­æ–‡æ–‡æœ¬ã€æ ‡ç‚¹ç¬¦å·ã€æ•°å­—ã€NPCå’Œç²¾çµåå­—

æ•°æ®:
{data_str}

è¾“å‡ºè¦æ±‚:
1. æœ‰é—®é¢˜è¾“å‡ºJSONæ•°ç»„ï¼Œæ— é—®é¢˜è¾“å‡º[]
2. ç¦æ­¢```jsonæ ‡è®°ï¼Œç¦æ­¢ä»»ä½•è§£é‡Šæ–‡å­—
3. æ ¼å¼:[{{"line_no":260,"issue":"é—®é¢˜ç±»å‹ï¼šå…·ä½“é—®é¢˜","suggestion":"ä¿®æ”¹å»ºè®®"}}]
4. line_noå¿…é¡»æ˜¯æ•°å­—ï¼Œå­—ç¬¦ä¸²å€¼ç”¨è‹±æ–‡åŒå¼•å·
5. å¿…é¡»ä»¥[å¼€å§‹]ç»“æŸï¼Œç¡®ä¿å®Œæ•´

ç›´æ¥è¾“å‡º:"""
    return prompt

def check_ollama_models():
    """
    æ£€æŸ¥Ollamaå¯ç”¨çš„æ¨¡å‹åˆ—è¡¨
    
    Returns:
        list: å¯ç”¨çš„æ¨¡å‹åç§°åˆ—è¡¨ï¼Œå¦‚æœå¤±è´¥è¿”å›None
    """
    try:
        response = requests.get(f"{OLLAMA_API_URL}/tags", timeout=5)
        if response.status_code == 200:
            models_data = response.json()
            models = [model['name'] for model in models_data.get('models', [])]
            return models
        else:
            print(f"âš ï¸ è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: HTTP {response.status_code}")
            return None
    except Exception as e:
        print(f"âš ï¸ æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡: {e}")
        return None

def check_model_health(model_name):
    """
    æ£€æŸ¥æ¨¡å‹å¥åº·åº¦ï¼Œå¦‚æœæ¨¡å‹æœªè¿è¡Œåˆ™è‡ªåŠ¨å¯åŠ¨
    
    Args:
        model_name: æ¨¡å‹åç§°
    
    Returns:
        bool: æ¨¡å‹æ˜¯å¦å¥åº·å¯ç”¨
    """
    print(f"ğŸ¥ æ­£åœ¨æ£€æŸ¥æ¨¡å‹å¥åº·åº¦: {model_name}")
    
    # 1. æ£€æŸ¥OllamaæœåŠ¡æ˜¯å¦å¯è®¿é—®
    try:
        response = requests.get(f"{OLLAMA_API_URL}/tags", timeout=5)
        if response.status_code != 200:
            print(f"âŒ OllamaæœåŠ¡ä¸å¯ç”¨ (HTTP {response.status_code})")
            return False
    except Exception as e:
        print(f"âŒ æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡: {e}")
        print(f"ğŸ’¡ è¯·ç¡®ä¿OllamaæœåŠ¡æ­£åœ¨è¿è¡Œ")
        return False
    
    # 2. æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²åŠ è½½ï¼ˆé€šè¿‡å°è¯•ç”Ÿæˆæ¥æµ‹è¯•ï¼‰
    print(f"ğŸ” æµ‹è¯•æ¨¡å‹å“åº”...")
    test_payload = {
        "model": model_name,
        "prompt": "æµ‹è¯•",
        "stream": False,
        "options": {
            "temperature": 0.1,  # ä½æ¸©åº¦ä¿è¯ç»“æœç¡®å®šæ€§
            "num_ctx": 8192,     # ä¸Šä¸‹æ–‡çª—å£
            "num_gpu": 99,       # ä½¿ç”¨æ‰€æœ‰å¯ç”¨GPU
            "num_predict": 1     # æµ‹è¯•åªéœ€è¦ç”Ÿæˆ1ä¸ªtoken
        }
    }
    
    try:
        response = requests.post(OLLAMA_URL, json=test_payload, timeout=10)
        if response.status_code == 200:
            print(f"âœ… æ¨¡å‹å¥åº·æ£€æŸ¥é€šè¿‡: {model_name}")
            return True
        elif response.status_code == 404:
            print(f"âš ï¸ æ¨¡å‹æœªåŠ è½½ï¼Œæ­£åœ¨å¯åŠ¨æ¨¡å‹...")
            return start_model(model_name)
        else:
            print(f"âš ï¸ æ¨¡å‹å“åº”å¼‚å¸¸ (HTTP {response.status_code})")
            return False
    except requests.exceptions.Timeout:
        print(f"âš ï¸ æ¨¡å‹å“åº”è¶…æ—¶ï¼Œå¯èƒ½æœªåŠ è½½ï¼Œæ­£åœ¨å¯åŠ¨æ¨¡å‹...")
        return start_model(model_name)
    except Exception as e:
        print(f"âš ï¸ æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        return False

def start_model(model_name):
    """
    å¯åŠ¨æŒ‡å®šçš„Ollamaæ¨¡å‹
    
    Args:
        model_name: æ¨¡å‹åç§°
    
    Returns:
        bool: å¯åŠ¨æ˜¯å¦æˆåŠŸ
    """
    print(f"ğŸš€ æ­£åœ¨å¯åŠ¨æ¨¡å‹: {model_name}")
    print(f"ğŸ“ æ‰§è¡Œå‘½ä»¤: ollama run {model_name}")
    
    try:
        import subprocess
        # ä½¿ç”¨subprocesså¯åŠ¨æ¨¡å‹ï¼ˆåå°è¿è¡Œï¼‰
        # æ³¨æ„ï¼šollama run ä¼šåŠ è½½æ¨¡å‹åˆ°å†…å­˜
        process = subprocess.Popen(
            ["ollama", "run", model_name, "--verbose"],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            stdin=subprocess.PIPE,
            text=True
        )
        
        # å‘é€ä¸€ä¸ªç®€å•çš„æµ‹è¯•è¾“å…¥å¹¶ç«‹å³é€€å‡º
        try:
            process.stdin.write("æµ‹è¯•\n")
            process.stdin.write("/bye\n")
            process.stdin.flush()
        except:
            pass
        
        # ç­‰å¾…æ¨¡å‹åŠ è½½ï¼ˆå¤§æ¨¡å‹éœ€è¦è¾ƒé•¿æ—¶é—´ï¼‰
        print(f"â³ ç­‰å¾…æ¨¡å‹åŠ è½½ï¼ˆçº¦15-30ç§’ï¼‰...")
        time.sleep(15)
        
        # éªŒè¯æ¨¡å‹æ˜¯å¦æˆåŠŸåŠ è½½ï¼ˆå¤šæ¬¡å°è¯•ï¼‰
        test_payload = {
            "model": model_name,
            "prompt": "æµ‹è¯•",
            "stream": False,
            "options": {
                "temperature": 0.1,  # ä½æ¸©åº¦ä¿è¯ç»“æœç¡®å®šæ€§
                "num_ctx": 8192,     # ä¸Šä¸‹æ–‡çª—å£
                "num_gpu": 99,       # ä½¿ç”¨æ‰€æœ‰å¯ç”¨GPU
                "num_predict": 1     # æµ‹è¯•åªéœ€è¦ç”Ÿæˆ1ä¸ªtoken
            }
        }
        
        max_retries = 3
        for i in range(max_retries):
            try:
                print(f"ğŸ” éªŒè¯æ¨¡å‹çŠ¶æ€ ({i+1}/{max_retries})...")
                response = requests.post(OLLAMA_URL, json=test_payload, timeout=30)
                if response.status_code == 200:
                    print(f"âœ… æ¨¡å‹å¯åŠ¨æˆåŠŸ: {model_name}")
                    return True
                else:
                    print(f"âš ï¸ æ¨¡å‹å“åº”å¼‚å¸¸ (HTTP {response.status_code})")
                    if i < max_retries - 1:
                        print(f"â³ ç­‰å¾…5ç§’åé‡è¯•...")
                        time.sleep(5)
            except requests.exceptions.Timeout:
                print(f"âš ï¸ éªŒè¯è¶…æ—¶")
                if i < max_retries - 1:
                    print(f"â³ ç­‰å¾…5ç§’åé‡è¯•...")
                    time.sleep(5)
            except Exception as e:
                print(f"âš ï¸ éªŒè¯å‡ºé”™: {e}")
                if i < max_retries - 1:
                    print(f"â³ ç­‰å¾…5ç§’åé‡è¯•...")
                    time.sleep(5)
        
        print(f"âŒ æ¨¡å‹å¯åŠ¨å¤±è´¥ï¼Œå·²å°è¯• {max_retries} æ¬¡")
        return False
            
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ° ollama å‘½ä»¤")
        print(f"ğŸ’¡ è¯·ç¡®ä¿ Ollama å·²æ­£ç¡®å®‰è£…å¹¶æ·»åŠ åˆ°ç³»ç»Ÿ PATH")
        return False
    except Exception as e:
        print(f"âŒ å¯åŠ¨æ¨¡å‹æ—¶å‡ºé”™: {e}")
        return False

def verify_model_exists(model_name):
    """
    éªŒè¯æŒ‡å®šçš„æ¨¡å‹æ˜¯å¦å­˜åœ¨ï¼Œå¹¶æ£€æŸ¥å¥åº·åº¦
    
    Args:
        model_name: æ¨¡å‹åç§°
    
    Returns:
        bool: æ¨¡å‹æ˜¯å¦å­˜åœ¨ä¸”å¥åº·
    """
    print(f"ğŸ” æ­£åœ¨éªŒè¯æ¨¡å‹: {model_name}")
    models = check_ollama_models()
    
    if models is None:
        print(f"âš ï¸ æ— æ³•éªŒè¯æ¨¡å‹ï¼Œå°†å°è¯•ç›´æ¥ä½¿ç”¨")
        return True  # æ— æ³•éªŒè¯æ—¶å‡è®¾æ¨¡å‹å­˜åœ¨ï¼Œè®©åç»­è°ƒç”¨æ¥å¤„ç†é”™è¯¯
    
    if model_name in models:
        print(f"âœ… æ¨¡å‹å­˜åœ¨: {model_name}")
        # è¿›è¡Œå¥åº·åº¦æ£€æŸ¥
        return check_model_health(model_name)
    else:
        print(f"âŒ é”™è¯¯: æ¨¡å‹ '{model_name}' ä¸å­˜åœ¨ï¼")
        print(f"ğŸ“‹ å½“å‰Ollamaä¸­å¯ç”¨çš„æ¨¡å‹:")
        for i, model in enumerate(models, 1):
            print(f"   {i}. {model}")
        print(f"\nğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
        print(f"   1. ä¿®æ”¹è„šæœ¬ä¸­çš„ MODEL_NAME ä¸ºä¸Šè¿°æ¨¡å‹ä¹‹ä¸€")
        print(f"   2. æˆ–è€…ä½¿ç”¨å‘½ä»¤ä¸‹è½½æ¨¡å‹: ollama pull {model_name}")
        return False

def call_ollama(prompt):
    """
    è°ƒç”¨æœ¬åœ° Ollama æ¥å£
    
    Args:
        prompt: æç¤ºè¯
    
    Returns:
        str: æ¨¡å‹å“åº”æ–‡æœ¬ï¼Œå¤±è´¥è¿”å›None
    """
    payload = {
        "model": MODEL_NAME,
        "prompt": prompt,
        "stream": False,
        "options": {
            "temperature": 0.1, # ä½æ¸©åº¦ä¿è¯ç»“æœç¡®å®šæ€§
            "num_ctx": 8192,     # ä¸Šä¸‹æ–‡çª—å£ï¼ˆå¢å¤§ä»¥æ”¯æŒæ›´é•¿çš„è¾“å…¥ï¼‰
            "num_gpu": 99,    # ä½¿ç”¨æ‰€æœ‰å¯ç”¨GPU
            "num_predict": 4096,  # æœ€å¤§ç”Ÿæˆé•¿åº¦ï¼ˆä»1024å¢åŠ åˆ°4096ï¼Œé¿å…æˆªæ–­ï¼‰
            "stop": ["\n\n\n", "ã€å¾…æ£€æŸ¥æ•°æ®ã€‘", "ç°åœ¨å¼€å§‹æ£€æŸ¥"] # å¼ºåˆ¶åœæ­¢ç¬¦
        }
    }
    
    try:
        response = requests.post(OLLAMA_URL, json=payload, timeout=300)
        if response.status_code == 200:
            return response.json().get("response", "")
        else:
            print(f"âŒ Ollama APIé”™è¯¯ (HTTP {response.status_code}): {response.text}")
            if response.status_code == 404:
                print(f"ğŸ’¡ æç¤º: æ¨¡å‹ '{MODEL_NAME}' å¯èƒ½ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥æ¨¡å‹åç§°")
            return None
    except requests.exceptions.Timeout:
        print(f"âŒ è¯·æ±‚è¶…æ—¶: æ¨¡å‹å“åº”æ—¶é—´è¿‡é•¿ï¼ˆ>300ç§’ï¼‰")
        return None
    except Exception as e:
        print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")
        return None

def parse_llm_response(response_text, batch_info=""):
    """
    å°è¯•è§£æ LLM è¿”å›çš„ JSONï¼Œæ”¯æŒå¤šç§æ ¼å¼å’Œå®¹é”™å¤„ç†
    
    Args:
        response_text: LLMè¿”å›çš„åŸå§‹æ–‡æœ¬
        batch_info: æ‰¹æ¬¡ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰
    
    Returns:
        list: è§£æåçš„é—®é¢˜åˆ—è¡¨ï¼Œè§£æå¤±è´¥è¿”å›ç©ºåˆ—è¡¨
    """
    if not response_text or not response_text.strip():
        print(f"âš ï¸ LLMè¿”å›äº†ç©ºå“åº” {batch_info}")
        return []
    
    try:
        # æ­¥éª¤1: æ¸…ç†Markdownæ ‡è®°å’Œä¸­æ–‡å¼•å·
        clean_text = response_text.strip()
        clean_text = clean_text.replace("```json", "").replace("```", "").strip()
        
        # æ›¿æ¢ä¸­æ–‡å¼•å·ä¸ºè‹±æ–‡å¼•å·ï¼ˆé¿å…JSONè§£æé”™è¯¯ï¼‰
        clean_text = clean_text.replace(""", '"').replace(""", '"')
        clean_text = clean_text.replace("'", "'").replace("'", "'")
        
        # æ­¥éª¤2: å°è¯•æ‰¾åˆ°JSONæ•°ç»„çš„è¾¹ç•Œ
        start = clean_text.find("[")
        end = clean_text.rfind("]")
        
        if start == -1:
            print(f"âŒ æœªæ‰¾åˆ°JSONæ•°ç»„å¼€å§‹ç¬¦å· [ {batch_info}")
            print(f"ğŸ“„ å“åº”å†…å®¹å‰200å­—ç¬¦: {response_text[:200]}")
            return []
        
        if end == -1 or start >= end:
            # å¯èƒ½æ˜¯æˆªæ–­çš„JSONï¼Œå°è¯•æŸ¥æ‰¾ä¸å®Œæ•´çš„æ•°ç»„
            print(f"âš ï¸ JSONæ•°ç»„æœªæ­£ç¡®é—­åˆï¼Œå°è¯•ä¿®å¤... {batch_info}")
            json_str = clean_text[start:]
            fixed_json = try_fix_truncated_json(json_str)
            if fixed_json:
                clean_text = fixed_json
                end = clean_text.rfind("]")
                if end == -1:
                    print(f"âŒ ä¿®å¤å¤±è´¥ï¼šä»ç„¶æ²¡æœ‰æ‰¾åˆ°é—­åˆç¬¦å· {batch_info}")
                    return []
            else:
                print(f"âŒ æœªæ‰¾åˆ°ä»»ä½•å®Œæ•´çš„å¯¹è±¡ {batch_info}")
                print(f"ğŸ“„ å“åº”å†…å®¹å‰200å­—ç¬¦: {response_text[:200]}")
                return []
        
        # æå–JSONå­—ç¬¦ä¸²ï¼ˆåŒ…å«å®Œæ•´çš„ [ ... ]ï¼‰
        json_str = clean_text[start:end + 1]
        
        # æ­¥éª¤3: å°è¯•ç›´æ¥è§£æ
        try:
            result = json.loads(json_str)
            if isinstance(result, list):
                print(f"âœ… æˆåŠŸè§£æJSONï¼Œå‘ç° {len(result)} ä¸ªé—®é¢˜ {batch_info}")
                return result
            else:
                print(f"âš ï¸ JSONæ ¼å¼é”™è¯¯ï¼šæœŸæœ›åˆ—è¡¨ï¼Œå®é™…ä¸º {type(result)} {batch_info}")
                return []
        except json.JSONDecodeError as e:
            # æ­¥éª¤4: å¦‚æœç›´æ¥è§£æå¤±è´¥ï¼Œå°è¯•ä¿®å¤å¸¸è§é—®é¢˜
            print(f"âš ï¸ JSONè§£æå¤±è´¥: {str(e)} {batch_info}")
            print(f"ğŸ“ é”™è¯¯ä½ç½®: ç¬¬{e.lineno}è¡Œ, ç¬¬{e.colno}åˆ— (char {e.pos})")
            
            # ã€æ–°å¢ã€‘å°è¯•æ›´æ¿€è¿›çš„æ¸…ç†ç­–ç•¥ï¼ˆå¤„ç†æ§åˆ¶å­—ç¬¦ï¼‰
            print(f"ğŸ”§ å°è¯•æ¸…ç†æ§åˆ¶å­—ç¬¦å’Œç‰¹æ®Šå­—ç¬¦... {batch_info}")
            json_str_cleaned = clean_json_string(json_str)
            if json_str_cleaned != json_str:
                try:
                    result = json.loads(json_str_cleaned)
                    if isinstance(result, list):
                        print(f"âœ… æ¸…ç†åæˆåŠŸè§£æJSONï¼Œå‘ç° {len(result)} ä¸ªé—®é¢˜ {batch_info}")
                        return result
                except json.JSONDecodeError as e2:
                    print(f"âš ï¸ æ¸…ç†åä»ç„¶å¤±è´¥: {str(e2)} {batch_info}")
            
            # å°è¯•ä¿®å¤ï¼šå¤„ç†æˆªæ–­çš„JSON
            print(f"ğŸ”§ å°è¯•ä¿®å¤æˆªæ–­çš„JSON... {batch_info}")
            fixed_json = try_fix_truncated_json(json_str_cleaned if json_str_cleaned != json_str else json_str)
            if fixed_json:
                try:
                    result = json.loads(fixed_json)
                    if isinstance(result, list):
                        print(f"âœ… ä¿®å¤åæˆåŠŸè§£æJSONï¼Œå‘ç° {len(result)} ä¸ªé—®é¢˜ {batch_info}")
                        return result
                except Exception as e3:
                    print(f"âš ï¸ ä¿®å¤åè§£æå¤±è´¥: {str(e3)} {batch_info}")
            
            # å¦‚æœä¿®å¤å¤±è´¥ï¼Œä¿å­˜åŸå§‹å“åº”ç”¨äºè°ƒè¯•
            import re
            # æ¸…ç†batch_infoï¼Œåªä¿ç•™æ•°å­—å’Œä¸‹åˆ’çº¿
            safe_batch_info = re.sub(r'[^0-9_]', '', batch_info.replace(' ', '_').replace('æ‰¹æ¬¡', 'batch').replace('/', '_'))
            debug_file = f"llm_debug_{safe_batch_info}.txt"
            try:
                with open(debug_file, "w", encoding="utf-8") as f:
                    f.write(f"=== æ‰¹æ¬¡ä¿¡æ¯ ===\n")
                    f.write(f"{batch_info}\n\n")
                    f.write("=== åŸå§‹å“åº” ===\n")
                    f.write(response_text)
                    f.write("\n\n=== æ¸…ç†åçš„JSON ===\n")
                    f.write(json_str)
                    f.write("\n\n=== é”™è¯¯ä¿¡æ¯ ===\n")
                    f.write(f"é”™è¯¯: {str(e)}\n")
                    f.write(f"ä½ç½®: ç¬¬{e.lineno}è¡Œ, ç¬¬{e.colno}åˆ—\n")
                    if fixed_json:
                        f.write("\n\n=== ä¿®å¤åçš„JSON ===\n")
                        f.write(fixed_json)
                print(f"ğŸ’¾ è°ƒè¯•ä¿¡æ¯å·²ä¿å­˜: {debug_file}")
            except Exception as save_err:
                print(f"âš ï¸ æ— æ³•ä¿å­˜è°ƒè¯•æ–‡ä»¶: {save_err}")
            
            print(f"âŒ JSONè§£æå¤±è´¥ {batch_info}")
            print(f"ğŸ“„ JSONå‰200å­—ç¬¦: {json_str[:200]}")
            if len(json_str) > 500:
                print(f"ğŸ“„ JSONå200å­—ç¬¦: {json_str[-200:]}")
            
            return []
    
    except Exception as e:
        print(f"âŒ è§£æè¿‡ç¨‹å‘ç”Ÿå¼‚å¸¸: {e}")
        return []

def clean_json_string(json_str):
    """
    æ¸…ç†JSONå­—ç¬¦ä¸²ä¸­çš„é—®é¢˜å­—ç¬¦ï¼ˆå¢å¼ºç‰ˆï¼‰
    """
    import re
    
    # 1. ç§»é™¤ASCIIæ§åˆ¶å­—ç¬¦ï¼ˆ0x00-0x1Fï¼‰
    cleaned = re.sub(r'[\x00-\x08\x0B\x0C\x0E-\x1F]', '', json_str)
    
    # 2. æ›¿æ¢ä¸­æ–‡ç¬¦å·ä¸ºè‹±æ–‡ç¬¦å·
    cleaned = cleaned.replace('ï¼Œ', ',').replace('ï¼š', ':')
    cleaned = cleaned.replace('"', '"').replace('"', '"')
    cleaned = cleaned.replace(''', "'").replace(''', "'")
    
    # 3. å¤„ç†å­—ç¬¦ä¸²å€¼å†…çš„ç‰¹æ®Šå­—ç¬¦
    def escape_special_chars(match):
        content = match.group(1)
        content = content.replace('\n', '\\n').replace('\r', '\\r').replace('\t', '\\t')
        return f'"{content}"'
    
    try:
        cleaned = re.sub(r'"([^"]*)"', escape_special_chars, cleaned)
    except Exception as e:
        print(f"âš ï¸ å­—ç¬¦è½¬ä¹‰å¤±è´¥: {e}")
    
    return cleaned

def try_fix_truncated_json(json_str):
    """
    å°è¯•ä¿®å¤æˆªæ–­çš„JSONå­—ç¬¦ä¸²ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
    """
    try:
        # å…ˆæ¸…ç†
        json_str = clean_json_string(json_str)
        
        # ç©ºæ•°ç»„ç›´æ¥è¿”å›
        if json_str.strip() == "[]":
            return json_str
        
        # æŸ¥æ‰¾æ•°ç»„è¾¹ç•Œ
        start = json_str.find("[")
        end = json_str.rfind("]")
        
        if start == -1:
            return None
        
        # æœªé—­åˆçš„æ•°ç»„
        if end == -1 or start >= end:
            print(f"ğŸ”§ ä¿®å¤æœªé—­åˆçš„æ•°ç»„...")
            
            # æ‰¾åˆ°æœ€åä¸€ä¸ªå®Œæ•´å¯¹è±¡
            last_brace = json_str.rfind("}")
            if last_brace == -1:
                print(f"âš ï¸ æœªæ‰¾åˆ°å®Œæ•´å¯¹è±¡")
                return None
            
            # ä»åå¾€å‰æŸ¥æ‰¾æ‹¬å·åŒ¹é…çš„ä½ç½®
            positions = [i for i, c in enumerate(json_str) if c == '}']
            
            for pos in reversed(positions):
                before = json_str[:pos + 1]
                if before.count("{") == before.count("}"):
                    fixed = before + "]"  # ç›´æ¥é—­åˆï¼Œä¸åŠ æ¢è¡Œ
                    print(f"âœ… ä¿ç•™ {before.count('}')} ä¸ªå®Œæ•´å¯¹è±¡")
                    return fixed
            
            print(f"âš ï¸ æ‹¬å·ä¸åŒ¹é…: {{ {json_str.count('{')} ä¸ª, }} {json_str.count('}')} ä¸ª")
            return None
        
        # å·²é—­åˆä½†å¯èƒ½æœ‰é—®é¢˜
        last_brace = json_str.rfind("}")
        if last_brace > -1:
            after = json_str[last_brace + 1:end].strip()
            if after in ["", ","]:
                return json_str
            # ç§»é™¤å¤šä½™å†…å®¹
            return json_str[:last_brace + 1] + "]"
        
        return json_str
    
    except Exception as e:
        print(f"âš ï¸ ä¿®å¤å¤±è´¥: {e}")
        return None

def load_excel_with_multirow_header(file_path, sheet_name, header_rows=None):
    """
    åŠ è½½Excelæ–‡ä»¶ï¼Œæ”¯æŒå¤šè¡Œè¡¨å¤´
    
    Args:
        file_path: Excelæ–‡ä»¶è·¯å¾„
        sheet_name: Sheetåç§°
        header_rows: è¡¨å¤´è¡Œé…ç½®
            - None: è‡ªåŠ¨æ£€æµ‹ï¼ˆé»˜è®¤ç¬¬ä¸€è¡Œï¼‰
            - int: å•è¡Œè¡¨å¤´çš„è¡Œå·ï¼ˆ0-basedï¼‰
            - list: å¤šè¡Œè¡¨å¤´çš„è¡Œå·åˆ—è¡¨ï¼Œå¦‚ [0, 1, 2]
    
    Returns:
        df: DataFrame
        actual_header_rows: å®é™…ä½¿ç”¨çš„è¡¨å¤´è¡Œæ•°ï¼ˆç”¨äºè®¡ç®—Excelè¡Œå·ï¼‰
    """
    try:
        if header_rows is None:
            # é»˜è®¤å•è¡Œè¡¨å¤´
            df = pd.read_excel(file_path, sheet_name=sheet_name, header=0)
            actual_header_rows = 1
            print(f"âœ… ä½¿ç”¨é»˜è®¤å•è¡Œè¡¨å¤´ï¼ˆç¬¬1è¡Œï¼‰")
        elif isinstance(header_rows, int):
            # å•è¡Œè¡¨å¤´ï¼ŒæŒ‡å®šè¡Œå·
            df = pd.read_excel(file_path, sheet_name=sheet_name, header=header_rows)
            actual_header_rows = header_rows + 1
            print(f"âœ… ä½¿ç”¨å•è¡Œè¡¨å¤´ï¼ˆç¬¬{header_rows + 1}è¡Œï¼‰")
        elif isinstance(header_rows, list):
            # å¤šè¡Œè¡¨å¤´
            df = pd.read_excel(file_path, sheet_name=sheet_name, header=header_rows)
            actual_header_rows = max(header_rows) + 1
            
            # åˆå¹¶å¤šè¡Œè¡¨å¤´ä¸ºå•ä¸€åˆ—å
            # pandasä¼šè‡ªåŠ¨åˆ›å»ºMultiIndexï¼Œæˆ‘ä»¬éœ€è¦å°†å…¶å±•å¹³
            if isinstance(df.columns, pd.MultiIndex):
                # åˆå¹¶å¤šå±‚åˆ—åï¼Œç”¨ä¸‹åˆ’çº¿è¿æ¥ï¼Œå»é™¤ç©ºå€¼
                df.columns = [
                    '_'.join([str(c) for c in col if str(c) != 'nan' and str(c).strip() != ''])
                    for col in df.columns.values
                ]
                print(f"âœ… ä½¿ç”¨å¤šè¡Œè¡¨å¤´ï¼ˆç¬¬{min(header_rows)+1}-{max(header_rows)+1}è¡Œï¼‰ï¼Œå·²åˆå¹¶åˆ—å")
            else:
                print(f"âœ… ä½¿ç”¨å¤šè¡Œè¡¨å¤´ï¼ˆç¬¬{min(header_rows)+1}-{max(header_rows)+1}è¡Œï¼‰")
        else:
            raise ValueError(f"header_rows å‚æ•°æ ¼å¼é”™è¯¯: {header_rows}")
        
        return df, actual_header_rows
    
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}", flush=True)
        import traceback
        traceback.print_exc()
        raise

def find_target_column(df, target_column_name, column_index=None):
    """
    æŸ¥æ‰¾ç›®æ ‡åˆ—ï¼Œæ”¯æŒæ¨¡ç³ŠåŒ¹é…å’Œå¤šåˆ—é€‰æ‹©
    
    Args:
        df: DataFrame
        target_column_name: ç›®æ ‡åˆ—å
        column_index: å¯é€‰ï¼Œå½“å­˜åœ¨å¤šä¸ªåŒ¹é…åˆ—æ—¶ï¼ŒæŒ‡å®šä½¿ç”¨ç¬¬å‡ ä¸ªï¼ˆä»0å¼€å§‹ï¼‰
    
    Returns:
        actual_column_name: å®é™…æ‰¾åˆ°çš„åˆ—åï¼Œå¦‚æœæœªæ‰¾åˆ°è¿”å›None
    """
    matched_columns = []
    
    # 1. ç²¾ç¡®åŒ¹é…
    exact_matches = [col for col in df.columns if col == target_column_name]
    if exact_matches:
        matched_columns.extend(exact_matches)
    
    # 2. æ¨¡ç³ŠåŒ¹é…ï¼ˆå¿½ç•¥å¤§å°å†™å’Œç©ºæ ¼ï¼‰
    if not matched_columns:
        target_lower = target_column_name.lower().replace(' ', '')
        for col in df.columns:
            col_lower = str(col).lower().replace(' ', '')
            if target_lower in col_lower or col_lower in target_lower:
                matched_columns.append(col)
    
    # 3. å¤„ç†åŒ¹é…ç»“æœ
    if not matched_columns:
        # æœªæ‰¾åˆ°ï¼Œåˆ—å‡ºæ‰€æœ‰åˆ—åä¾›å‚è€ƒ
        print(f"âŒ é”™è¯¯: æ²¡æ‰¾åˆ°åˆ—å '{target_column_name}'")
        print(f"ğŸ“‹ å½“å‰è¡¨æ ¼çš„æ‰€æœ‰åˆ—å:")
        for i, col in enumerate(df.columns, 1):
            print(f"   {i}. {col}")
        print(f"\nğŸ’¡ æç¤º: è¯·ä¿®æ”¹è„šæœ¬ä¸­çš„ TARGET_COLUMN é…ç½®ä¸ºä¸Šè¿°åˆ—åä¹‹ä¸€")
        return None
    
    # 4. å¦‚æœæ‰¾åˆ°å¤šä¸ªåŒ¹é…åˆ—
    if len(matched_columns) > 1:
        print(f"âš ï¸ æ‰¾åˆ° {len(matched_columns)} ä¸ªåŒ¹é…çš„åˆ—:")
        for i, col in enumerate(matched_columns):
            print(f"   [{i}] {col}")
        
        # æ ¹æ®column_indexé€‰æ‹©
        if column_index is not None:
            if 0 <= column_index < len(matched_columns):
                selected_col = matched_columns[column_index]
                print(f"âœ… ä½¿ç”¨ç¬¬ {column_index} ä¸ªåŒ¹é…åˆ—: '{selected_col}'")
                return selected_col
            else:
                print(f"âŒ é”™è¯¯: TARGET_COLUMN_INDEX={column_index} è¶…å‡ºèŒƒå›´ (0-{len(matched_columns)-1})")
                return None
        else:
            # é»˜è®¤ä½¿ç”¨ç¬¬ä¸€ä¸ª
            selected_col = matched_columns[0]
            print(f"âœ… é»˜è®¤ä½¿ç”¨ç¬¬ä¸€ä¸ªåŒ¹é…åˆ—: '{selected_col}'")
            print(f"ğŸ’¡ æç¤º: å¦‚éœ€ä½¿ç”¨å…¶ä»–åˆ—ï¼Œè¯·è®¾ç½® TARGET_COLUMN_INDEX (0-{len(matched_columns)-1})")
            return selected_col
    
    # 5. åªæ‰¾åˆ°ä¸€ä¸ªåŒ¹é…åˆ—
    selected_col = matched_columns[0]
    if selected_col == target_column_name:
        print(f"âœ… æ‰¾åˆ°ç›®æ ‡åˆ—ï¼ˆç²¾ç¡®åŒ¹é…ï¼‰: '{selected_col}'")
    else:
        print(f"âœ… æ‰¾åˆ°ç›®æ ‡åˆ—ï¼ˆæ¨¡ç³ŠåŒ¹é…ï¼‰: '{selected_col}' (é…ç½®ä¸­ä¸º: '{target_column_name}')")
    return selected_col

def main():
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) >= 4:
        input_file = sys.argv[1]
        sheet_name = sys.argv[2]
        target_column = sys.argv[3]
    else:
        # ä½¿ç”¨é»˜è®¤é…ç½®
        input_file = INPUT_FILE
        sheet_name = SHEET_NAME
        target_column = TARGET_COLUMN
    
    # åŠ¨æ€ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
    output_file = f"{sheet_name}_{target_column}_Check_Report_{datetime.now().strftime('%Y%m%d')}.xlsx"
    
    print("=" * 60, flush=True)
    print("ğŸš€ é…ç½®æ–‡æœ¬æ£€æŸ¥å·¥å…· v2.3 (GPUåŠ é€Ÿç‰ˆ)", flush=True)
    print("=" * 60, flush=True)
    
    # æ˜¾ç¤ºå½“å‰é…ç½®
    print(f"ğŸ“‹ å½“å‰é…ç½®:")
    print(f"   - æ¨¡å‹åç§°: {MODEL_NAME}")
    print(f"   - Ollamaåœ°å€: {OLLAMA_URL}")
    print(f"   - è¾“å…¥æ–‡ä»¶: {input_file}")
    print(f"   - Sheetåç§°: {sheet_name}")
    print(f"   - ç›®æ ‡åˆ—: {target_column}")
    print(f"   - æ‰¹æ¬¡å¤§å°: {BATCH_SIZE} è¡Œ/æ‰¹")
    print("-" * 60)
    
    # éªŒè¯æ¨¡å‹æ˜¯å¦å­˜åœ¨
    if not verify_model_exists(MODEL_NAME):
        print("\nâŒ æ¨¡å‹éªŒè¯å¤±è´¥ï¼Œç¨‹åºç»ˆæ­¢")
        print("ğŸ’¡ è¯·ä¿®æ”¹è„šæœ¬ä¸­çš„ MODEL_NAME é…ç½®æˆ–ä¸‹è½½å¯¹åº”æ¨¡å‹")
        return
    
    print("-" * 60)
    
    # åŠ è½½Excelæ–‡ä»¶ï¼ˆæ”¯æŒå¤šè¡Œè¡¨å¤´ï¼‰
    try:
        df, header_row_count = load_excel_with_multirow_header(
            input_file, 
            sheet_name, 
            HEADER_ROWS
        )
    except Exception as e:
        return
    
    print(f"ğŸ“Š æ•°æ®è¡Œæ•°: {len(df)} è¡Œ")
    print(f"ğŸ“Š åˆ—æ•°: {len(df.columns)} åˆ—")
    print("-" * 60)
    
    # æŸ¥æ‰¾ç›®æ ‡åˆ—
    actual_column = find_target_column(df, target_column, TARGET_COLUMN_INDEX)
    if actual_column is None:
        return
    
    # é¢„å¤„ç†ï¼šç­›é€‰å‡ºéç©ºä¸”åŒ…å«ä¸­æ–‡çš„è¡Œï¼ˆå‡å°‘æ— æ•ˆè¯·æ±‚ï¼‰
    # è¿™é‡Œå‡è®¾æˆ‘ä»¬åªæ£€æŸ¥å­—ç¬¦ä¸²ç±»å‹çš„å•å…ƒæ ¼
    df_to_check = df[df[actual_column].apply(lambda x: isinstance(x, str) and len(x) > 1)].copy()
    
    # è®°å½•åŸå§‹è¡Œå·ï¼ˆExcelè¡Œå· = DataFrameçš„index + è¡¨å¤´è¡Œæ•° + 1ï¼‰
    # ä¾‹å¦‚ï¼š3è¡Œè¡¨å¤´ï¼ŒDataFrameç¬¬0è¡Œ = Excelç¬¬4è¡Œ
    df_to_check['excel_row'] = df_to_check.index + header_row_count + 1
    
    total_rows = len(df_to_check)
    print(f"âœ… å…±å‘ç° {total_rows} è¡Œæœ‰æ•ˆæ–‡æœ¬ï¼Œå¼€å§‹åˆ†æ‰¹æ£€æŸ¥...")
    print(f"ğŸ“¦ æ‰¹æ¬¡å¤§å°: {BATCH_SIZE} è¡Œ/æ‰¹")
    print("-" * 60)

    all_issues = []

    # åˆ†æ‰¹å¤„ç†
    batches = math.ceil(total_rows / BATCH_SIZE)
    failed_batches = []  # è®°å½•å¤±è´¥çš„æ‰¹æ¬¡
    interrupted = False  # æ ‡è®°æ˜¯å¦è¢«ä¸­æ–­
    completed_batches = 0  # å·²å®Œæˆçš„æ‰¹æ¬¡æ•°
    
    try:
        for i in tqdm(range(batches), desc="AI æ£€æŸ¥è¿›åº¦"):
            start_idx = i * BATCH_SIZE
            end_idx = min((i + 1) * BATCH_SIZE, total_rows)
            batch_num = i + 1
            
            # æå–å½“å‰æ‰¹æ¬¡æ•°æ®
            current_batch = df_to_check.iloc[start_idx:end_idx]
            
            # æ„é€ å‘é€ç»™ LLM çš„ç®€åŒ–æ•°æ®ç»“æ„ï¼š{è¡Œå·: æ–‡æœ¬}
            batch_payload = {
                row['excel_row']: row[actual_column] 
                for _, row in current_batch.iterrows()
            }
            
            # å‘é€ç»™ LLM
            prompt = get_check_prompt(batch_payload)
            response = call_ollama(prompt)
            
            if response:
                # è®°å½•å“åº”é•¿åº¦ï¼ˆç”¨äºè°ƒè¯•ï¼‰
                response_len = len(response)
                
                # è§£æå“åº”
                batch_info = f"(æ‰¹æ¬¡ {batch_num}/{batches})"
                issues = parse_llm_response(response, batch_info)
                
                if issues:
                    all_issues.extend(issues)
                    # ä¸åœ¨è¿›åº¦æ¡ä¸­æ‰“å°ï¼Œé¿å…å¹²æ‰°
                elif response_len > 10:
                    # å¦‚æœå“åº”ä¸ä¸ºç©ºä½†è§£æå¤±è´¥ï¼Œè®°å½•å¤±è´¥çš„æ‰¹æ¬¡
                    failed_batches.append({
                        'batch': batch_num,
                        'rows': f"{list(batch_payload.keys())[0]}-{list(batch_payload.keys())[-1]}",
                        'response_len': response_len
                    })
            else:
                # APIè°ƒç”¨å¤±è´¥
                failed_batches.append({
                    'batch': batch_num,
                    'rows': f"{list(batch_payload.keys())[0]}-{list(batch_payload.keys())[-1]}",
                    'response_len': 0,
                    'error': 'APIè°ƒç”¨å¤±è´¥'
                })
            
            # ç¨å¾®ä¼‘çœ ä¸€ä¸‹é˜²æ­¢ GPU è¿‡çƒ­æˆ– Ollama å µå¡ï¼ˆå¯é€‰ï¼‰
            # time.sleep(0.1)
            completed_batches = i + 1
    except KeyboardInterrupt:
        interrupted = True
        print(f"\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­ï¼å·²å®Œæˆ {completed_batches}/{batches} æ‰¹æ¬¡", flush=True)
        print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜å·²æ£€æŸ¥çš„ç»“æœ...", flush=True)
    
    # å¤„ç†å®Œæˆåï¼Œæ˜¾ç¤ºå¤±è´¥çš„æ‰¹æ¬¡ä¿¡æ¯
    if failed_batches:
        print(f"\nâš ï¸ æœ‰ {len(failed_batches)} ä¸ªæ‰¹æ¬¡å¤„ç†å¤±è´¥æˆ–è§£æå¤±è´¥:")
        for fb in failed_batches:
            error_msg = fb.get('error', 'JSONè§£æå¤±è´¥')
            print(f"   - æ‰¹æ¬¡ {fb['batch']} (è¡Œå· {fb['rows']}): {error_msg}, å“åº”é•¿åº¦: {fb['response_len']} å­—ç¬¦")
        print(f"ğŸ’¡ æç¤º: æ£€æŸ¥ llm_response_debug.txt æ–‡ä»¶æŸ¥çœ‹è¯¦ç»†çš„å“åº”å†…å®¹")

    # ç»“æœè¾“å‡º
    if all_issues:
        result_df = pd.DataFrame(all_issues)
        # è°ƒæ•´åˆ—é¡ºåº
        cols = ["line_no", "issue", "suggestion"]
        # ç¡®ä¿åˆ—å­˜åœ¨ï¼ˆé˜²æ­¢ LLM è¿”å›çš„ key ä¸å¯¹ï¼‰
        for c in cols:
            if c not in result_df.columns:
                result_df[c] = ""
        
        result_df = result_df[cols]
        result_df.columns = ["è¡Œå·", "é—®é¢˜è¯´æ˜", "ä¿®æ”¹å»ºè®®"]
        
        # ä½¿ç”¨å®‰å…¨ä¿å­˜å‡½æ•°
        final_output_file = safe_save_excel(result_df, output_file)
        print(f"\næ£€æŸ¥å®Œæˆï¼å…±å‘ç° {len(all_issues)} å¤„æ½œåœ¨é—®é¢˜ã€‚")
        print(f"ç»“æœå·²ä¿å­˜è‡³: {final_output_file}")
        
        # è¿½åŠ åŠŸèƒ½ï¼šæ’å…¥åŸæ–‡å†…å®¹
        print("-" * 60)
        print("ğŸ“ æ­£åœ¨æ·»åŠ é…ç½®åŸæ–‡...")
        add_original_text_to_report(final_output_file, input_file, sheet_name, actual_column, header_row_count)
    else:
        print("\næ£€æŸ¥å®Œæˆï¼æœªå‘ç°æ˜æ˜¾é—®é¢˜ï¼ˆæˆ–è€…æ¨¡å‹æœªèƒ½æ­£ç¡®è¾“å‡ºï¼‰ã€‚")

def safe_save_excel(df, file_path, max_retries=3):
    """
    å®‰å…¨ä¿å­˜Excelæ–‡ä»¶ï¼Œå¤„ç†æ–‡ä»¶è¢«å ç”¨çš„æƒ…å†µ
    
    Args:
        df: è¦ä¿å­˜çš„DataFrame
        file_path: ç›®æ ‡æ–‡ä»¶è·¯å¾„
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
    
    Returns:
        str: å®é™…ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
    """
    for attempt in range(max_retries):
        try:
            # å°è¯•ä¿å­˜æ–‡ä»¶
            df.to_excel(file_path, index=False)
            return file_path
        except PermissionError as e:
            if attempt < max_retries - 1:
                print(f"âš ï¸ æ–‡ä»¶è¢«å ç”¨ï¼Œ{2}ç§’åé‡è¯•... (å°è¯• {attempt + 1}/{max_retries})")
                time.sleep(2)
            else:
                # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥ï¼Œç”Ÿæˆæ–°æ–‡ä»¶å
                print(f"âŒ æ–‡ä»¶ '{file_path}' è¢«å ç”¨ï¼ˆå¯èƒ½åœ¨Excelä¸­æ‰“å¼€ï¼‰")
                
                # ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–°æ–‡ä»¶å
                base_name = os.path.splitext(file_path)[0]
                ext = os.path.splitext(file_path)[1]
                timestamp = datetime.now().strftime('%H%M%S')
                new_file_path = f"{base_name}_{timestamp}{ext}"
                
                try:
                    df.to_excel(new_file_path, index=False)
                    print(f"âœ… å·²ä¿å­˜ä¸ºæ–°æ–‡ä»¶: {new_file_path}")
                    print(f"ğŸ’¡ æç¤º: è¯·å…³é—­Excelä¸­çš„æ–‡ä»¶åå†è¿è¡Œè„šæœ¬")
                    return new_file_path
                except Exception as e2:
                    print(f"âŒ ä¿å­˜å¤±è´¥: {e2}")
                    raise
        except Exception as e:
            print(f"âŒ ä¿å­˜æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            raise
    
    return file_path

def add_original_text_to_report(output_file, input_file, sheet_name, target_column, header_row_count):
    """
    ä»è¾“å‡ºæŠ¥å‘Šä¸­è¯»å–è¡Œå·ï¼Œä»åŸå§‹Excelæ–‡ä»¶ä¸­è·å–å¯¹åº”è¡Œçš„åŸæ–‡ï¼Œ
    å¹¶æ’å…¥åˆ°æŠ¥å‘Šçš„ç¬¬ä¸€åˆ—ä¹‹å
    
    Args:
        output_file: è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        input_file: åŸå§‹Excelæ–‡ä»¶è·¯å¾„
        sheet_name: Sheetåç§°
        target_column: ç›®æ ‡åˆ—å
        header_row_count: è¡¨å¤´è¡Œæ•°
    """
    try:
        # 1. è¯»å–è¾“å‡ºæŠ¥å‘Š
        report_df = pd.read_excel(output_file)
        print(f"âœ… è¯»å–æŠ¥å‘Šæ–‡ä»¶: {len(report_df)} è¡Œ")
        
        # 2. è¯»å–åŸå§‹Excelæ–‡ä»¶
        original_df, _ = load_excel_with_multirow_header(input_file, sheet_name, HEADER_ROWS)
        print(f"âœ… è¯»å–åŸå§‹æ–‡ä»¶: {len(original_df)} è¡Œ")
        
        # 3. ä¸ºæ¯ä¸€è¡Œè·å–åŸæ–‡å’Œç¬¬ä¸€åˆ—çš„id
        original_texts = []
        first_column_ids = []
        
        # è·å–åŸå§‹Excelçš„ç¬¬ä¸€åˆ—åˆ—å
        first_column_name = original_df.columns[0]
        print(f"ğŸ“‹ ç¬¬ä¸€åˆ—åˆ—å: {first_column_name}")
        
        for idx, row in report_df.iterrows():
            line_no = row['è¡Œå·']
            try:
                # Excelè¡Œå·è½¬æ¢ä¸ºDataFrameç´¢å¼•
                # Excelè¡Œå· = DataFrameç´¢å¼• + è¡¨å¤´è¡Œæ•° + 1
                # æ‰€ä»¥ DataFrameç´¢å¼• = Excelè¡Œå· - è¡¨å¤´è¡Œæ•° - 1
                df_index = int(line_no) - header_row_count - 1
                
                if 0 <= df_index < len(original_df):
                    # è·å–åŸæ–‡
                    original_text = original_df.iloc[df_index][target_column]
                    # å¤„ç†NaNå€¼
                    if pd.isna(original_text):
                        original_text = ""
                    original_texts.append(str(original_text))
                    
                    # è·å–ç¬¬ä¸€åˆ—çš„id
                    first_column_value = original_df.iloc[df_index][first_column_name]
                    if pd.isna(first_column_value):
                        first_column_value = ""
                    first_column_ids.append(str(first_column_value))
                else:
                    print(f"âš ï¸ è­¦å‘Š: è¡Œå· {line_no} è¶…å‡ºèŒƒå›´")
                    original_texts.append("")
                    first_column_ids.append("")
            except Exception as e:
                print(f"âš ï¸ è­¦å‘Š: æ— æ³•è·å–è¡Œå· {line_no} çš„æ•°æ®: {e}")
                original_texts.append("")
                first_column_ids.append("")
        
        # 4. åœ¨ç¬¬ä¸€åˆ—ä¹‹åæ’å…¥"é…ç½®åŸæ–‡"åˆ—ï¼Œåœ¨ç¬¬äºŒåˆ—ä½ç½®æ’å…¥"id"åˆ—
        report_df.insert(1, 'é…ç½®åŸæ–‡', original_texts)
        report_df.insert(2, 'å¯¹ç™½id', first_column_ids)
        
        # 5. ä¿å­˜æ›´æ–°åçš„æŠ¥å‘Šï¼ˆä½¿ç”¨å®‰å…¨ä¿å­˜ï¼‰
        final_file = safe_save_excel(report_df, output_file)
        print(f"âœ… å·²æ·»åŠ é…ç½®åŸæ–‡å’Œidåˆ°æŠ¥å‘Šæ–‡ä»¶")
        print(f"ğŸ“Š æœ€ç»ˆæŠ¥å‘Š: {len(report_df)} è¡Œ Ã— {len(report_df.columns)} åˆ—")
        print(f"ğŸ“‹ åˆ—å: {', '.join(report_df.columns.tolist())}")
        if final_file != output_file:
            print(f"ğŸ’¡ æ³¨æ„: åŸæ–‡ä»¶è¢«å ç”¨ï¼Œå·²ä¿å­˜ä¸º: {final_file}")
        
    except Exception as e:
        print(f"âŒ æ·»åŠ åŸæ–‡å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='æ¸¸æˆé…ç½®æ–‡æœ¬æ£€æŸ¥å·¥å…·')
    parser.add_argument('input_file', nargs='?', default=INPUT_FILE, help='Excelé…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('sheet_name', nargs='?', default=SHEET_NAME, help='Sheetåç§°')
    parser.add_argument('target_column', nargs='?', default=TARGET_COLUMN, help='ç›®æ ‡åˆ—å')
    parser.add_argument('--batch-size', type=int, default=BATCH_SIZE, help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--model', default=MODEL_NAME, help='æ¨¡å‹åç§°')
    parser.add_argument('--column-index', type=int, default=TARGET_COLUMN_INDEX, help='åˆ—ç´¢å¼•')
    
    args = parser.parse_args()
    
    # æ›´æ–°å…¨å±€é…ç½®
    INPUT_FILE = args.input_file
    SHEET_NAME = args.sheet_name
    TARGET_COLUMN = args.target_column
    BATCH_SIZE = args.batch_size
    MODEL_NAME = args.model
    TARGET_COLUMN_INDEX = args.column_index
    OUTPUT_FILE = f"{SHEET_NAME}_{TARGET_COLUMN}_Check_Report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
    
    main()